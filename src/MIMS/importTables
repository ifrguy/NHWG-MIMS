#!/bin/bash -e
## Copyright 2025 Marshall E. Giguere
##
##   Licensed under the Apache License, Version 2.0 (the "License");
##   you may not use this file except in compliance with the License.
##   You may obtain a copy of the License at
##
##       https://www.apache.org/licenses/LICENSE-2.0
##
##   Unless required by applicable law or agreed to in writing, software
##   distributed under the License is distributed on an "AS IS" BASIS,
##   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
##   See the License for the specific language governing permissions and
##   limitations under the License.


# importTables: imports CAPWATCH, or any csv file, into MongoDB.
# By default collections are "dropped" and recreated before import. You
# may optionally select either the "i" import only, or "u" upsert
# (insert new or update old documents).  The "i" option is useful for
# populating newly created empty collections.  The "u" upsert option is used
# to update existing collections.
# By default all collections/tables listed in the "TABLES" variable are imported
# unless you specify a different list on the command line.
# NOTES:
# 0. All configuration varilables are stored in "importTables.conf" in
#    the same location as this script.
# 1. For each csv file you MUST supply a ".types" file declaring the type of
#    each column in the csv file. The name of the file must be the basename
#    of the csv file with the extension ".types" and be stored in the location
#    specified by the  TYPEPATH variable.
# 2. For each csv file to be "upserted" you must include in the "UPFIELDS" array
#    (see importTables.conf) the names of the fields to be used for comparison.
#
# Import/upsert CAPWATCH tables into MongoDB. User may change the database or
# provide a list of substitute tables to import.
# Note 1: All tables must have a companion .types file for mongoimport
# Note 2: Files must have been preprocessed with getTables before importing
#         or similar to convert dates to MicroSoft SQL date format.
# Note 3: If indexing you must supply the appropriate MongoDB JavaScript
#         for each collection to preform the indexing operation.
#         Index script naming convention:
#          <table name>-index.js
#
# History:
# 22Mar21 MEG Index option now call ops function to do it's work.
# 18Mar21 MEG Added import option "i". Changed index option from "i" to "I".
# 18Mar21 MEG changed all ".types" files date format conversion funcs.
# 26Aug19 MEG Moved configurable options to a conf file.
# 29Jul19 MEG Added per and post import javascript per collection eval.
# 28Nov18 MEG Abort import if CAPWATCH download failed.
# 30Aug18 MEG Indexing now on per collection basis.
# 29Aug18 MEG Option to update or import with collection drop.
# 12Aug18 MEG Index script config variable added
# 20Jul18 MEG Index CAPWATCH collections.
# 24Jun18 MEG Check for missing import files.
# 25Mar18 MEG Now imports Commanders table.
# 22Jan18 MEG Move MongoDB login cred's to separate file.
# 13Jul17 MEG User option to change database and substitute tables.
# 03Jul17 MEG Created.
#

# Function to call to load CAPWATCH data into MongoDB (drop|import|upsert)
CALL="drop"

# Upsert fields for each table
# Fields to match on import.  If these fields match the record is updated,
# if not a new record is inserted into the collection.
declare -A UPFIELDS
UPFIELDS[Commanders]='ORGID'
UPFIELDS[Member]='CAPID'
UPFIELDS[MbrContact]='CAPID,Type,Priority'
UPFIELDS[MbrAddresses]='CAPID,Type,Priority'
UPFIELDS[MbrAchievements]='CAPID,AchvID'
UPFIELDS[DutyPosition]='CAPID,Duty,FunctArea,Lvl,Asst,ORGID'
UPFIELDS[equipment]='assetcd'
UPFIELDS[Organization]='ORGID'
UPFIELDS[OrgAddresses]='ORGID,Type'

# Check to see if download was successful
if [ -f CAPWATCHFAILED ]; then
    echo "ERROR: CAPWATCH download failed not importing tables!"
    exit 1
fi

# Load configurations options
# Note conf file must be in the same directory as this script.
CONF=./$(basename $0).conf
if [[ -f $CONF ]]; then
    . $CONF
else
    echo "Error: configuration file: $CONF not found."
    exit 1
fi

# load Mongo MIMS importer credentials
. $CREDS

# Command options
OPTS="d:iIt:h?u"

# Help text
USAGE="Usage: $(basename $0) [$OPTS] [table table...] \n
\tReplace or update CAPWATCH collection(s) in $DB MongoDB. \n
\td - database ($DB)\n
\ti - import table simply import data into table (may result in duplicates)\n
\tI - Call script to index collections post import\n
\th|? - help, this message.\n
\tt - path to .type files ($TYPEPATH)\n
\tu - Update collections instead of replace\n
\tTABLES=$TABLES\n"

# Drops collection and imports them fresh.
# All data for the collection including indices are removed
# prior to importing the new data.
function drop() {
    $IMPORT --db $DB --authenticationDatabase=$DB --username=$MONGOUID \
--password=$MONGOPASS --collection $1 --drop --type csv --columnsHaveTypes \
	--fieldFile $TYPEPATH/$1.types --file $1.csv

}
# Imports data into the collection.
# No checking for duplicates or other checks, simply pulls the file
# into the collection.  Good for populating a new empty collection
function import() {
    $IMPORT --db $DB --authenticationDatabase=$DB --username=$MONGOUID \
--password=$MONGOPASS --collection $1 --type csv --columnsHaveTypes \
	--fieldFile $TYPEPATH/$1.types --file $1.csv

}

# Updates collection inserting new records if required.  No indexing
# of collections.  Collections are assumed to already have appropriate
# indexes.
function upsert() {
    $IMPORT --db $DB --authenticationDatabase=$DB --username=$MONGOUID \
--password=$MONGOPASS --collection $t --type csv --columnsHaveTypes \
	--fieldFile $TYPEPATH/$1.types --upsertFields ${UPFIELDS[$t]} --file $1.csv
}

# ops - runs the supplied JavaScript program either before,
# or after the import of a collection.  The scripts can do 
# anything within the privileges of the user: create, drop, remove, index...
# collection, as complicated as you want.
# Collections may have index, pre and post scripts identified by:
# <collectionName>-[index|pre|post].js.
function ops() {
    [ ! -f $1 ] && return
    echo "Ops: $1"
    mongosh --quiet --authenticationDatabase=$DB --username=$MONGOUID \
		--password=$MONGOPASS $1
}


while getopts $OPTS o; do
    case $o in
	d) DB=$OPTARG;;
	i) CALL="import";;
	I) INDEX="yes";;
	u) CALL="upsert";;
	t) TYPEPATH=$OPTARG;;
	h|?) echo -e $USAGE;exit 1;;
	*) echo -e $USAGE;exit 1;;
    esac
done
shift $(($OPTIND - 1))

# Check for substituted list of tables to import
if [ $# -ge 1 ]; then
    TABLES=$@
fi

# remove old import failure flag if it exists
if [ -f "IMPORTFAILED" ]; then
    /bin/rm -f IMPORTFAILED
fi

for t in $TABLES; do
    echo "Importing table: $t"
    if [ ! -f "$t.csv" ]; then
	echo "ERROR: file not found: $t.csv"
	touch IMPORTFAILED
	continue
    fi
    # run pre import script if one exists
    ops "$t-pre.js"
    $CALL $t
    # run post import script if one exists
    ops "$t-post.js"
done

# Index collections
if [ -v INDEX ]; then
    for t in $TABLES; do
	echo "Indexing: $t"
	ops "$t-index.js"
    done
fi

echo "Done."
